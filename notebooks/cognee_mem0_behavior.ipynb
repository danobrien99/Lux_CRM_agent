{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cognee + Mem0 Behavior Workbook\n",
        "\n",
        "This notebook traces the **exact app pipeline** used in Lux CRM for a message:\n",
        "\n",
        "1. Raw message text -> `extract_candidates` (Cognee adapter)\n",
        "2. Candidates -> `candidates_to_claims`\n",
        "3. Claim bundle -> `propose_memory_ops` (Mem0 adapter)\n",
        "4. Ops -> graph-ready relation payloads (same logic as worker)\n",
        "\n",
        "It supports two modes:\n",
        "- **Real adapters**: use your configured Cognee/Mem0/OpenAI/DB stack\n",
        "- **Deterministic fallback**: force local heuristic/rules behavior for debugging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "from pprint import pprint\n",
        "\n",
        "# Resolve repo root regardless of where Jupyter starts.\n",
        "cwd = Path.cwd().resolve()\n",
        "if (cwd / \"apps\" / \"api\").exists():\n",
        "    repo_root = cwd\n",
        "elif (cwd.parent / \"apps\" / \"api\").exists():\n",
        "    repo_root = cwd.parent\n",
        "else:\n",
        "    raise RuntimeError(\"Run this notebook from repo root or notebooks/ directory.\")\n",
        "\n",
        "api_root = repo_root / \"apps\" / \"api\"\n",
        "if str(api_root) not in sys.path:\n",
        "    sys.path.insert(0, str(api_root))\n",
        "\n",
        "print(f\"repo_root={repo_root}\")\n",
        "print(f\"api_root={api_root}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional: force deterministic local fallback mode.\n",
        "# Set to True if you want reproducible behavior without live Cognee/Mem0/LLM dependencies.\n",
        "FORCE_DETERMINISTIC_FALLBACK = False\n",
        "\n",
        "if FORCE_DETERMINISTIC_FALLBACK:\n",
        "    os.environ[\"COGNEE_BACKEND\"] = \"unknown\"\n",
        "    os.environ[\"COGNEE_ENABLE_HEURISTIC_FALLBACK\"] = \"true\"\n",
        "    os.environ[\"MEM0_BACKEND\"] = \"unknown\"\n",
        "    os.environ[\"MEM0_ENABLE_RULES_FALLBACK\"] = \"true\"\n",
        "    print(\"Deterministic fallback mode enabled.\")\n",
        "else:\n",
        "    print(\"Using configured adapters from environment.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from app.core.config import get_settings\n",
        "\n",
        "get_settings.cache_clear()\n",
        "settings = get_settings()\n",
        "\n",
        "summary = {\n",
        "    \"llm_provider\": settings.llm_provider,\n",
        "    \"llm_model\": settings.llm_model,\n",
        "    \"embedding_provider\": settings.embedding_provider,\n",
        "    \"embedding_model\": settings.embedding_model,\n",
        "    \"embedding_dim\": settings.embedding_dim,\n",
        "    \"cognee_backend\": settings.cognee_backend,\n",
        "    \"cognee_local_module\": settings.cognee_local_module,\n",
        "    \"cognee_search_type\": settings.cognee_search_type,\n",
        "    \"cognee_search_top_k\": settings.cognee_search_top_k,\n",
        "    \"cognee_enable_heuristic_fallback\": settings.cognee_enable_heuristic_fallback,\n",
        "    \"mem0_backend\": settings.mem0_backend,\n",
        "    \"mem0_local_module\": settings.mem0_local_module,\n",
        "    \"mem0_search_limit\": settings.mem0_search_limit,\n",
        "    \"mem0_enable_rules_fallback\": settings.mem0_enable_rules_fallback,\n",
        "    \"auto_accept_threshold\": settings.auto_accept_threshold,\n",
        "}\n",
        "\n",
        "pprint(summary)\n",
        "print(\"OPENAI_API_KEY set:\", bool(os.getenv(\"OPENAI_API_KEY\")))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example Inputs\n",
        "\n",
        "Edit or add message payloads below to test different extraction behavior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "samples = [\n",
        "    {\n",
        "        \"interaction_id\": \"demo-interaction-001\",\n",
        "        \"text\": (\n",
        "            \"Great to catch up. We should plan the Nature Investment Hub workshop next month. \"\n",
        "            \"My daughter just started at Stanford and schedules are tight, but I can do Tuesday afternoon. \"\n",
        "            \"Also, I moved into the Head of Partnerships role at Acme Ventures.\"\n",
        "        ),\n",
        "        \"contact_id\": \"demo-contact-001\",\n",
        "    },\n",
        "    {\n",
        "        \"interaction_id\": \"demo-interaction-002\",\n",
        "        \"text\": (\n",
        "            \"Thanks for the intro. I am evaluating whether we should run a pilot in Q2. \"\n",
        "            \"No firm budget yet; let us keep this exploratory and share proposal options.\"\n",
        "        ),\n",
        "        \"contact_id\": \"demo-contact-002\",\n",
        "    },\n",
        "]\n",
        "\n",
        "for s in samples:\n",
        "    print(\"-\", s[\"interaction_id\"], \"chars=\", len(s[\"text\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Cognee Extraction (`extract_candidates`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from app.services.extraction.cognee_client import extract_candidates\n",
        "\n",
        "cognee_results = {}\n",
        "\n",
        "for sample in samples:\n",
        "    interaction_id = sample[\"interaction_id\"]\n",
        "    text = sample[\"text\"]\n",
        "    try:\n",
        "        result = extract_candidates(interaction_id=interaction_id, text=text)\n",
        "        cognee_results[interaction_id] = result\n",
        "        print(\"\\n===\", interaction_id, \"===\")\n",
        "        print(\n",
        "            \"counts:\",\n",
        "            {\n",
        "                \"entities\": len(result.get(\"entities\", [])),\n",
        "                \"relations\": len(result.get(\"relations\", [])),\n",
        "                \"topics\": len(result.get(\"topics\", [])),\n",
        "            },\n",
        "        )\n",
        "        pprint(result)\n",
        "    except Exception as exc:\n",
        "        print(\"\\n===\", interaction_id, \"FAILED===\")\n",
        "        print(type(exc).__name__, str(exc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Candidate -> Claim Mapping (`candidates_to_claims`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from app.services.extraction.cognee_mapper import candidates_to_claims\n",
        "\n",
        "candidate_claims_by_interaction = {}\n",
        "for sample in samples:\n",
        "    interaction_id = sample[\"interaction_id\"]\n",
        "    candidates = cognee_results.get(interaction_id)\n",
        "    if not candidates:\n",
        "        continue\n",
        "    claims = candidates_to_claims(candidates)\n",
        "    candidate_claims_by_interaction[interaction_id] = claims\n",
        "    print(\"\\n===\", interaction_id, \"claims===\")\n",
        "    print(\"claim_count=\", len(claims))\n",
        "    pprint(claims)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Mem0 Bundle + Ops (`build_mem0_bundle` + `propose_memory_ops`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from app.services.memory.mem0_mapper import build_mem0_bundle\n",
        "from app.services.memory.mem0_client import propose_memory_ops\n",
        "\n",
        "mem0_ops_by_interaction = {}\n",
        "\n",
        "for sample in samples:\n",
        "    interaction_id = sample[\"interaction_id\"]\n",
        "    contact_id = sample[\"contact_id\"]\n",
        "    claims = candidate_claims_by_interaction.get(interaction_id, [])\n",
        "\n",
        "    prepared_claims = []\n",
        "    for c in claims:\n",
        "        c2 = dict(c)\n",
        "        c2[\"evidence_refs\"] = [\n",
        "            {\n",
        "                \"interaction_id\": interaction_id,\n",
        "                \"chunk_id\": f\"demo-chunk-{interaction_id}\",\n",
        "                \"span_json\": {\"start\": 0, \"end\": min(180, len(sample[\"text\"]))},\n",
        "            }\n",
        "        ]\n",
        "        prepared_claims.append(c2)\n",
        "\n",
        "    bundle = build_mem0_bundle(\n",
        "        interaction_summary=sample[\"text\"][:280].strip(),\n",
        "        recent_claims=[],\n",
        "        cognee_candidates=prepared_claims,\n",
        "        auto_accept_threshold=settings.auto_accept_threshold,\n",
        "        scope_ids={\n",
        "            \"user_id\": contact_id,\n",
        "            \"agent_id\": settings.mem0_agent_id,\n",
        "            \"run_id\": interaction_id,\n",
        "            \"contact_id\": contact_id,\n",
        "            \"interaction_id\": interaction_id,\n",
        "        },\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        ops = propose_memory_ops(bundle)\n",
        "        mem0_ops_by_interaction[interaction_id] = ops\n",
        "        print(\"\\n===\", interaction_id, \"mem0 ops===\")\n",
        "        print(\"ops_count=\", len(ops))\n",
        "        pprint(ops)\n",
        "    except Exception as exc:\n",
        "        print(\"\\n===\", interaction_id, \"mem0 FAILED===\")\n",
        "        print(type(exc).__name__, str(exc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Worker-Equivalent Claims + Relation Payloads\n",
        "\n",
        "This mirrors the transformation logic used before `upsert_relation_triple(...)` in `apps/api/app/workers/jobs.py`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def _normalized_text(value):\n",
        "    if not isinstance(value, str):\n",
        "        return \"\"\n",
        "    return \" \".join(value.split()).strip()\n",
        "\n",
        "\n",
        "def claims_from_ops(ops, interaction_id):\n",
        "    claims = []\n",
        "    for op in ops:\n",
        "        claim = dict(op.get(\"claim\") or {})\n",
        "        if not claim:\n",
        "            continue\n",
        "        operation = op.get(\"op\", \"ADD\")\n",
        "        if operation == \"REJECT\":\n",
        "            claim[\"status\"] = \"rejected\"\n",
        "        if operation not in {\"ADD\", \"UPDATE\", \"SUPERSEDE\", \"REJECT\"}:\n",
        "            continue\n",
        "        if not claim.get(\"evidence_refs\"):\n",
        "            claim[\"evidence_refs\"] = [\n",
        "                {\n",
        "                    \"interaction_id\": interaction_id,\n",
        "                    \"chunk_id\": f\"demo-chunk-{interaction_id}\",\n",
        "                    \"span_json\": {\"start\": 0, \"end\": 180},\n",
        "                }\n",
        "            ]\n",
        "        claims.append(claim)\n",
        "    return claims\n",
        "\n",
        "\n",
        "def relation_payload_from_claim(claim):\n",
        "    value_json = claim.get(\"value_json\")\n",
        "    if not isinstance(value_json, dict):\n",
        "        return None\n",
        "\n",
        "    claim_type = _normalized_text(claim.get(\"claim_type\"))\n",
        "    subject = _normalized_text(value_json.get(\"subject\")) or \"contact\"\n",
        "\n",
        "    predicate = _normalized_text(value_json.get(\"predicate\"))\n",
        "    if not predicate:\n",
        "        if claim_type == \"employment\":\n",
        "            predicate = \"works_at\"\n",
        "        elif claim_type == \"topic\":\n",
        "            predicate = \"discussed_topic\"\n",
        "        else:\n",
        "            predicate = \"related_to\"\n",
        "\n",
        "    object_name = (\n",
        "        _normalized_text(value_json.get(\"object\"))\n",
        "        or _normalized_text(value_json.get(\"company\"))\n",
        "        or _normalized_text(value_json.get(\"destination\"))\n",
        "        or _normalized_text(value_json.get(\"target\"))\n",
        "        or _normalized_text(value_json.get(\"label\"))\n",
        "    )\n",
        "    if not object_name:\n",
        "        return None\n",
        "\n",
        "    if object_name.lower() == subject.lower():\n",
        "        return None\n",
        "\n",
        "    object_kind = _normalized_text(value_json.get(\"object_type\")) or \"Entity\"\n",
        "    if claim_type == \"employment\" and object_kind == \"Entity\":\n",
        "        object_kind = \"Company\"\n",
        "    if claim_type == \"topic\" and _normalized_text(value_json.get(\"label\")):\n",
        "        object_kind = \"Topic\"\n",
        "\n",
        "    return {\n",
        "        \"subject_name\": subject,\n",
        "        \"predicate\": predicate,\n",
        "        \"object_name\": object_name,\n",
        "        \"subject_kind\": _normalized_text(value_json.get(\"subject_type\"))\n",
        "        or (\"Contact\" if subject == \"contact\" else \"Entity\"),\n",
        "        \"object_kind\": object_kind,\n",
        "    }\n",
        "\n",
        "\n",
        "for sample in samples:\n",
        "    interaction_id = sample[\"interaction_id\"]\n",
        "\n",
        "    cognee_claims = candidate_claims_by_interaction.get(interaction_id, [])\n",
        "    mem0_ops = mem0_ops_by_interaction.get(interaction_id, [])\n",
        "    mem0_claims = claims_from_ops(mem0_ops, interaction_id)\n",
        "\n",
        "    merged_claims = cognee_claims + mem0_claims\n",
        "    relation_payloads = []\n",
        "    for claim in merged_claims:\n",
        "        payload = relation_payload_from_claim(claim)\n",
        "        if payload:\n",
        "            relation_payloads.append(\n",
        "                {\n",
        "                    \"claim_id\": claim.get(\"claim_id\"),\n",
        "                    \"claim_type\": claim.get(\"claim_type\"),\n",
        "                    \"status\": claim.get(\"status\", \"proposed\"),\n",
        "                    \"confidence\": float(claim.get(\"confidence\", 0.0) or 0.0),\n",
        "                    \"source_system\": claim.get(\"source_system\"),\n",
        "                    \"relation\": payload,\n",
        "                    \"evidence_refs\": claim.get(\"evidence_refs\", []),\n",
        "                }\n",
        "            )\n",
        "\n",
        "    print(\"\\n===\", interaction_id, \"graph-ready relation payloads===\")\n",
        "    print(\"payload_count=\", len(relation_payloads))\n",
        "    pprint(relation_payloads)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optional: Live Neo4j Write Check\n",
        "\n",
        "Set `ENABLE_NEO4J_WRITE = True` only if you want to write demo relations into your graph.\n",
        "\n",
        "By default this cell is read-only and just shows the write arguments that would be sent to `upsert_relation_triple(...)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datetime import datetime, timezone\n",
        "\n",
        "ENABLE_NEO4J_WRITE = False\n",
        "\n",
        "def build_upsert_args(contact_id, interaction_id, relation_item):\n",
        "    rel = relation_item[\"relation\"]\n",
        "    return {\n",
        "        \"contact_id\": contact_id,\n",
        "        \"interaction_id\": interaction_id,\n",
        "        \"interaction_timestamp_iso\": datetime.now(timezone.utc).isoformat(),\n",
        "        \"subject_name\": rel[\"subject_name\"],\n",
        "        \"predicate\": rel[\"predicate\"],\n",
        "        \"object_name\": rel[\"object_name\"],\n",
        "        \"claim_id\": relation_item.get(\"claim_id\"),\n",
        "        \"confidence\": relation_item.get(\"confidence\", 0.0),\n",
        "        \"status\": relation_item.get(\"status\", \"proposed\"),\n",
        "        \"source_system\": relation_item.get(\"source_system\") or \"demo\",\n",
        "        \"uncertain\": relation_item.get(\"status\") != \"accepted\",\n",
        "        \"evidence_refs\": relation_item.get(\"evidence_refs\", []),\n",
        "        \"subject_kind\": rel[\"subject_kind\"],\n",
        "        \"object_kind\": rel[\"object_kind\"],\n",
        "    }\n",
        "\n",
        "if ENABLE_NEO4J_WRITE:\n",
        "    from app.db.neo4j.queries import upsert_relation_triple\n",
        "\n",
        "    print(\"Neo4j writes ENABLED\")\n",
        "else:\n",
        "    print(\"Neo4j writes DISABLED (dry run)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optional: Inspect Existing Contact Graph Signals\n",
        "\n",
        "Set `DEMO_CONTACT_ID` to inspect how stored graph triples feed scoring and drafting retrieval."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DEMO_CONTACT_ID = os.getenv(\"DEMO_CONTACT_ID\", \"\").strip()\n",
        "\n",
        "if not DEMO_CONTACT_ID:\n",
        "    print(\"Set DEMO_CONTACT_ID env var to inspect live graph signals.\")\n",
        "else:\n",
        "    from app.db.neo4j.queries import get_contact_graph_metrics, get_contact_graph_paths\n",
        "\n",
        "    metrics = get_contact_graph_metrics(DEMO_CONTACT_ID)\n",
        "    paths = get_contact_graph_paths(DEMO_CONTACT_ID, objective=\"follow up\", max_hops=3, limit=8)\n",
        "    print(\"metrics:\")\n",
        "    pprint(metrics)\n",
        "    print(\"\\npaths:\")\n",
        "    pprint(paths)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optional: Inspect Draft Retrieval Bundle\n",
        "\n",
        "This shows the hybrid retrieval object consumed by draft generation (vector chunks + graph snippets + graph paths)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not DEMO_CONTACT_ID:\n",
        "    print(\"Set DEMO_CONTACT_ID first.\")\n",
        "else:\n",
        "    from app.db.pg.session import SessionLocal\n",
        "    from app.services.drafting.retriever import build_retrieval_bundle\n",
        "\n",
        "    db = SessionLocal()\n",
        "    try:\n",
        "        bundle = build_retrieval_bundle(\n",
        "            db=db,\n",
        "            contact_id=DEMO_CONTACT_ID,\n",
        "            objective=\"follow up on recent priorities\",\n",
        "            allow_sensitive=False,\n",
        "        )\n",
        "        preview = {\n",
        "            \"contact\": bundle.get(\"contact\"),\n",
        "            \"objective\": bundle.get(\"objective\"),\n",
        "            \"hybrid_graph_query\": bundle.get(\"hybrid_graph_query\"),\n",
        "            \"graph_metrics\": bundle.get(\"graph_metrics\"),\n",
        "            \"graph_claim_snippets\": bundle.get(\"graph_claim_snippets\"),\n",
        "            \"graph_path_snippets\": bundle.get(\"graph_path_snippets\"),\n",
        "            \"email_context_snippets\": bundle.get(\"email_context_snippets\"),\n",
        "            \"relevant_chunk_count\": len(bundle.get(\"relevant_chunks\", [])),\n",
        "            \"graph_path_count\": len(bundle.get(\"graph_paths\", [])),\n",
        "        }\n",
        "        pprint(preview)\n",
        "    finally:\n",
        "        db.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Notes\n",
        "\n",
        "- If Cognee/Mem0 cells fail in real mode, check adapter env and credentials first.\n",
        "- In deterministic fallback mode, outputs come from local heuristic/rule code paths in this repo.\n",
        "- This workbook demonstrates transformation behavior; production persistence still occurs in worker `process_interaction(...)`."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
